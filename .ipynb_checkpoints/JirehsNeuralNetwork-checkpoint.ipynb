{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9078a808",
   "metadata": {},
   "source": [
    "# Jireh's Neural Network\n",
    "My attempt at creating a rough **3 layer neural network from scratch** by using just **NumPy** and a Sigmoid function from **SciPy** for my squashing/activiation function (*since calculus is fucking hard and its even harder to make my own calculus-using equation in python*) that performs image recognition on numerical handwriting. I think there is like 5000 similiar projects on kaggle but whatever.\n",
    "\n",
    "Also its JNN for short `(*>﹏<*)′"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f204dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31c134a",
   "metadata": {},
   "source": [
    "### Remember\n",
    "Refer to the code below for a refresher on NumPy Arrays (*I need this LOL*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5099b57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "[[ 5.  2.]\n",
      " [ 9.  0.]\n",
      " [ 0. 12.]]\n"
     ]
    }
   ],
   "source": [
    "a = numpy.zeros([3,2])\n",
    "print(a)\n",
    "\n",
    "a[0,0] = 5\n",
    "a[0,1] = 2\n",
    "a[1,0] = 9\n",
    "a[2,1] = 12\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d853d7b",
   "metadata": {},
   "source": [
    "### Remember\n",
    "\n",
    "In linear algebra, the dot product (also known as the scalar product or inner product) is a mathematical operation that takes two vectors of equal size and returns a scalar.\n",
    "\n",
    "The dot product of two vectors A and B is calculated by multiplying the corresponding elements of the vectors together and summing up the results. Specifically, for two vectors A and B with the same number of elements (n), the dot product can be written as:\n",
    "\n",
    "A · B = A1 * B1 + A2 * B2 + ... + An * Bn\n",
    "\n",
    "Where A1, A2, ..., An and B1, B2, ..., Bn are the corresponding elements of the two vectors.\n",
    "\n",
    "#### Furthermore\n",
    "In NumPy, the dot function is a method for computing the dot product between two arrays. The dot function can be used to perform dot products of various types of arrays, including 1-dimensional arrays, 2-dimensional arrays (matrices), and higher-dimensional arrays.\n",
    "\n",
    "In the example below, we have two 2D arrays A and B, with dimensions 2x3 and 3x2, respectively. We compute their dot product using the dot function, and assign the result to a new 2D array C.\n",
    "\n",
    "The dot product of A and B is computed as a matrix multiplication, where the rows of A are multiplied by the columns of B. Since A has 2 rows and B has 2 columns, the resulting matrix C has dimensions 2x2.\n",
    "\n",
    "This is the result of computing the dot product of A and B. Each element in C is the dot product of a row in A and a column in B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f47dfdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 58  64]\n",
      " [139 154]]\n"
     ]
    }
   ],
   "source": [
    "# Define two 2D arrays\n",
    "A = numpy.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "\n",
    "B = numpy.array([[7, 8],\n",
    "              [9, 10],\n",
    "              [11, 12]])\n",
    "\n",
    "# Compute the dot product\n",
    "C = numpy.dot(A, B)\n",
    "\n",
    "# Print the result\n",
    "print(C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e57943",
   "metadata": {},
   "source": [
    "### Thus\n",
    "I will be using NumPy's dot function for calculating the matrixes of the weights in between the layers of my network. The weights between nodes and their outputs will be represented using 2-D NumPy arrays\n",
    "\n",
    "My neural network will only have one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16512301",
   "metadata": {},
   "outputs": [],
   "source": [
    "class jirehsNeuralNetwork:\n",
    "    \n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        \n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        self.lr = learningrate\n",
    "        \n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        \n",
    "        # weights from a normal probability distribution centred around zero \n",
    "        # and with a standard deviation that is related to the number of incoming links into a node, \n",
    "        # 1/√(number of incoming links)\n",
    "        \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        # centre of the normal distribution to 0.0\n",
    "        # expression for the standard deviation related to the number of nodes in next layer \n",
    "        # in Python form as pow(self.hnodes, -0.5) which is simply raising the number of nodes to the power of -0.5\n",
    "        # That last parameter is the shape of the numpy array we want.\n",
    "        \n",
    "\n",
    "        # activation function is the sigmoid function\n",
    "        # takes x and returns scipy.special.expit(x) which is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        # see query for deconstruction\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "\n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # This code is almost exactly the same as that in the query() function, \n",
    "        # because we’re feeding forward the signal from the input layer to the \n",
    "        # final output layer in exactly the same way.\n",
    "\n",
    "        # error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        \n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        # numpy.dot() calculates the dot product of two arrays. \n",
    "        # it is being used to calculate the weighted sum of the errors in the output layer,\n",
    "        # as they propagate backwards through the network.\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # For the weights between the hidden and final layers, we use the output_errors. \n",
    "        # For the weights between the input and hidden layers, we use these hidden_errors we just calculated.\n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        # this is a translation of the formula below\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "\n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "\n",
    "        # The learning rate is self.lr and simply multiplied with the rest of the expression\n",
    "        # matrix multiplication done by numpy.dot()\n",
    "        # error and sigmoids from the next layer = * final_outputs * (1.0 - final_outputs)\n",
    "        # transposed outputs from the previous layer = numpy.transpose(inputs)\n",
    "        # += simply means increase the preceding variable by the next amount\n",
    "\n",
    "    # query the neural network (doen't train weights or anything it just runs the inputs through the network once)\n",
    "    def query(self, inputs_list):\n",
    "        \n",
    "        # convert inputs list to 2d array\n",
    "        # ndmin parameter is used to ensure that the resulting array has at least 2 dimensions, even if input list is 1-d\n",
    "        # important because the T operation that comes later only works on arrays with 2 or more dimensions.\n",
    "        # .T is a shorthand for the NumPy transpose method, which returns a new array with the axes transposed. \n",
    "        # In this case, it is transposing the newly created array from step 1 so that the rows become columns and viceversa\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "                \n",
    "        # calculate signals into hidden layer\n",
    "        # numpy.dot() is a NumPy function that calculates the dot product of two arrays. \n",
    "        # it is being used to calculate the weighted sum of the inputs to each neuron in the hidden layer.\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "            \n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "       \n",
    "        return final_outputs"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "bda965e3",
   "metadata": {},
   "source": [
    "### Remember\n",
    "\n",
    "The alpha is the learning rate, and the sigmoid is the squashing activation function. Remember that the * multiplication is the normal element by element multiplication, and the · dot is the matrix dot product. That last bit, the matrix of outputs from the previous layer, is transposed. In effect this means the column of outputs becomes a row of outputs. This is used in the **train()** function of the **jirehsNeuralNetwork** class for backpropagation\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fc5b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "\n",
    "learning_rate = 0.3\n",
    "\n",
    "\n",
    "# create instance of neural network\n",
    "n = jirehsNeuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n",
    "\n",
    "# test query\n",
    "n.query([1.0, 0.5, -1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ed616d",
   "metadata": {},
   "source": [
    "### Modifying the Neural Network for Image Recognition\n",
    "\n",
    "I will be using The MNIST Dataset of Handwritten Numbers sourced from http://yann.lecun.com/exdb/mnist/.\n",
    "\n",
    "Specifically, I will be using this dataset: http://pjreddie.com/projects/mnist-in-csv/ as it is in a much better format.\n",
    "\n",
    "Download links:\n",
    "- http://www.pjreddie.com/media/files/mnist_train.csv\n",
    "- http://www.pjreddie.com/media/files/mnist_test.csv\n",
    "\n",
    "The following are the links to a smaller subsets of the MNIST dataset in CSV format which will be used initially before the above datasets:\n",
    "\n",
    "- https://raw.githubusercontent.com/makeyourownneuralnetwork/makeyourownneuralnetwork/master/mnist_dataset/mnist_test_10.csv\n",
    "\n",
    "- https://raw.githubusercontent.com/makeyourownneuralnetwork/makeyourownneuralnetwork/master/mnist_dataset/mnist_train_100.csv\n",
    "\n",
    "The format of the csv files can be deconstructed as follows;\n",
    "- The first value is the label is the actual digit that the handwriting is supposed to represent, such as a \"7\" or a \"9\". This will be the target values of the neural network\n",
    "- The subsequent comma separated values, are the pixel values of the handwritten digit. The size of the pixel array is 28 by 28, so there are 784 values after the label\n",
    "\n",
    "In short the format is:\n",
    "- label, pix-11, pix-12, pix-13, ...\n",
    "- where pix-ij is the pixel in the ith row and jth column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f034da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(\"mnist_train_100.csv\", 'r')\n",
    "data_list = data_file.readlines()\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd38bece",
   "metadata": {},
   "source": [
    "#### Note\n",
    "Dont use readlines() because it reads the entire file into memory. Better to read one line at a time and do whatever work you need with each line, and then move onto the next line. It is more efficient to work on a line at a time, and not read the entire file into memory. However I'm too lazy to do that. Also the files are small and its easier for the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b00c6d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19c13696e20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_values = data_list[5].split(',')\n",
    "\n",
    "# numpy.asfarray() converts the text strings into real numbers and creates an array\n",
    "# the square brackets [1:] are used to take all except the first element of this list\n",
    "# .reshape((28,28)) makes sure the list of number is wrapped around every 28 elements to make a square matrix 28 by 28.\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a0615",
   "metadata": {},
   "source": [
    "### Ok, now what?\n",
    "I must rescale the input colour values from the larger range 0 to 255 to the much smaller range 0.01 - 1.0. The lower number range of 0.01 is used to avoid artificially killing weight updates. 0.99 is not used because 1.0 is ok for the inputs. It’s only for the outputs that I should avoid the impossible to reach 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6d97d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.06047059\n",
      " 0.10705882 0.39823529 0.48364706 0.03717647 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.13811765 0.59623529 0.81752941 0.98835294 0.98835294\n",
      " 0.98835294 0.57682353 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.16529412 0.60011765 0.95729412\n",
      " 0.98835294 0.99223529 0.87964706 0.82917647 0.98835294 0.91070588\n",
      " 0.16529412 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.06823529\n",
      " 0.60011765 0.93788235 0.98835294 0.98835294 0.98835294 0.84858824\n",
      " 0.13035294 0.15364706 0.98835294 0.98835294 0.24294118 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.38270588 0.98835294 0.98835294\n",
      " 0.98835294 0.98835294 0.85247059 0.12258824 0.01       0.15364706\n",
      " 0.98835294 0.98835294 0.24294118 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.71270588 0.98835294 0.98835294 0.86411765 0.65835294\n",
      " 0.12647059 0.01       0.01       0.30894118 0.98835294 0.98835294\n",
      " 0.24294118 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.11094118\n",
      " 0.50694118 0.23517647 0.09541176 0.01       0.01       0.01\n",
      " 0.01       0.39823529 0.98835294 0.98835294 0.24294118 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.61952941\n",
      " 0.98835294 0.98835294 0.24294118 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.43705882\n",
      " 0.47976471 0.48364706 0.47976471 0.79423529 0.98835294 0.76317647\n",
      " 0.02164706 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.04882353 0.21576471 0.70494118 0.99223529 0.99223529 1.\n",
      " 0.99223529 0.99223529 0.89517647 0.14588235 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.02941176 0.21964706 0.89129412 0.98835294\n",
      " 0.95341176 0.89517647 0.67       0.94952941 0.98835294 0.98835294\n",
      " 0.90682353 0.46423529 0.03329412 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.03329412\n",
      " 0.31282353 0.98835294 0.98835294 0.49529412 0.23905882 0.01\n",
      " 0.07988235 0.81752941 0.98835294 0.98835294 0.98835294 0.98835294\n",
      " 0.34776471 0.03717647 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.02941176 0.53411765 0.98835294 0.98835294\n",
      " 0.70882353 0.07211765 0.01       0.09152941 0.79811765 0.99223529\n",
      " 0.96894118 0.51082353 0.68164706 0.98835294 0.98835294 0.72435294\n",
      " 0.26623529 0.20023529 0.20023529 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.02164706\n",
      " 0.538      0.98835294 0.94564706 0.42152941 0.076      0.01\n",
      " 0.21576471 0.78647059 0.98835294 0.84858824 0.26235294 0.01\n",
      " 0.06435294 0.28952941 0.64282353 0.94564706 0.98835294 0.98835294\n",
      " 0.87576471 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.41764706 0.98835294 0.94952941\n",
      " 0.35164706 0.07988235 0.29341176 0.67       0.95729412 0.98835294\n",
      " 0.49917647 0.12258824 0.01       0.01       0.01       0.01\n",
      " 0.01       0.35552941 0.70882353 0.70882353 0.15364706 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.90682353 0.98835294 0.96117647 0.80588235 0.84858824\n",
      " 0.98835294 0.98835294 0.98835294 0.49141176 0.02164706 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.81364706\n",
      " 0.98835294 0.98835294 0.98835294 0.98835294 0.70105882 0.46035294\n",
      " 0.14976471 0.02552941 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.06047059 0.37105882 0.56517647\n",
      " 0.47976471 0.09929412 0.03329412 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01      ]\n"
     ]
    }
   ],
   "source": [
    "# Dividing the raw inputs which are in the range 0-255 by 255 will bring them into the range 0-1. \n",
    "# multiply by 0.99 to bring them into the range 0.0 - 0.99. \n",
    "# add 0.01 to shift them up to the desired range 0.01 to 1.00. \n",
    "scaled_input = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef48be",
   "metadata": {},
   "source": [
    "### ☆*: .｡. o(≧▽≦)o .｡.:*☆\n",
    "\n",
    "I am asking the neural network to classify the image and assign the correct label. That label is one of 10 numbers, from 0 to 9. That means the network should be able to have an output layer of 10 nodes, one for each of the possible answers, or labels. If the answer was “0” the first output layer node would fire and the rest should be silent. If the answer was “9” the last output layer node would fire and the rest would be silent. \n",
    "\n",
    "<img src=\"image2.jpeg\" style=\"width: 50%; height: auto;\">\n",
    "\n",
    "I will use the values 0.01 and 0.99, so the target for the label “5” should be [0.01, 0.01, 0.01, 0.01, 0.01, 0.99, 0.01, 0.01, 0.01, 0.01]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f35f05d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    }
   ],
   "source": [
    "# output nodes is 10\n",
    "onodes = 10\n",
    "\n",
    "# create an array filled with zeros\n",
    "targets = numpy.zeros(onodes) + 0.01\n",
    "\n",
    "# takes the first element of the MNIST dataset record, which is the training target label, and converts that string into an integer.\n",
    "targets[int(all_values[0])] = 0.99\n",
    "\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed5b50",
   "metadata": {},
   "source": [
    "### Training\n",
    "Above code just for demonstration. Below is for real now\n",
    "\n",
    "784 input nodes will be used because it is 28 x 28 which is the pixels that make up the handwritten number image.\n",
    "\n",
    "100 hidden nodes is a good number. Why? IDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8207232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new NN instance\n",
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate is 0.3 (idk why 0.3 so dont ask me)\n",
    "learning_rate = 0.3\n",
    "\n",
    "# create instance of NN\n",
    "n = jirehsNeuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n",
    "\n",
    "training_data_file = open(\"mnist_train_100.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "# go through all records in the training data set\n",
    "for record in training_data_list:\n",
    "\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "    # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "    targets = numpy.zeros(output_nodes) + 0.01\n",
    "\n",
    "    # all_values[0] is the target label for this record\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    \n",
    "    n.train(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c80817",
   "metadata": {},
   "source": [
    "### Testing （￣︶￣）↗　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3178e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_file = open(\"mnist_test_10.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c57dd5",
   "metadata": {},
   "source": [
    "#### But first lets check some shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "699f9547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "all_values = test_data_list[5].split(',')\n",
    "print(all_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "028f6aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19c136f8790>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f10a6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02668145],\n",
       "       [0.95450764],\n",
       "       [0.02202958],\n",
       "       [0.05881229],\n",
       "       [0.0240116 ],\n",
       "       [0.06973371],\n",
       "       [0.03651402],\n",
       "       [0.02931451],\n",
       "       [0.11480746],\n",
       "       [0.00400567]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ed256",
   "metadata": {},
   "source": [
    "Above code shows that the NN works. Observe that the 1th value of the array is the highest as such the NN can detect that the writing in the image is a one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc78ce1c",
   "metadata": {},
   "source": [
    "#### Back to testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1af7d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: 7 -- 7 :Prediction ✓\n",
      "Truth: 2 -- 0 :Prediction ✗\n",
      "Truth: 1 -- 1 :Prediction ✓\n",
      "Truth: 0 -- 0 :Prediction ✓\n",
      "Truth: 4 -- 4 :Prediction ✓\n",
      "Truth: 1 -- 1 :Prediction ✓\n",
      "Truth: 4 -- 4 :Prediction ✓\n",
      "Truth: 9 -- 3 :Prediction ✗\n",
      "Truth: 5 -- 4 :Prediction ✗\n",
      "Truth: 9 -- 7 :Prediction ✗\n",
      "\n",
      "Accuracy = 60.0 %\n"
     ]
    }
   ],
   "source": [
    "# performance scorecard that counts the accuracy (how many times a positive prediction occured)\n",
    "accuracy_count = []\n",
    "\n",
    "for record in test_data_list:\n",
    "\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    \n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        accuracy_count.append(1)\n",
    "        print(\"Truth:\", correct_label, \"--\", label, \":Prediction\", '\\u2713')\n",
    "    else:\n",
    "        accuracy_count.append(0)\n",
    "        print(\"Truth:\", correct_label, \"--\", label, \":Prediction\", '\\u2717')\n",
    "\n",
    "# calculate the performance score\n",
    "accuracy_count_array = numpy.asarray(accuracy_count)\n",
    "print (\"\\nAccuracy =\", (accuracy_count_array.sum() / accuracy_count_array.size) * 100 , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e5033b",
   "metadata": {},
   "source": [
    "### Full Datasets (´･ω･`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b9dda",
   "metadata": {},
   "source": [
    "#### Training\n",
    "This will take sometime, depending on how shit your PC is, as our dataset consists of 60,000 items?records?values?columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c556be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed\n",
      "Elapsed time: 27.46 seconds\n"
     ]
    }
   ],
   "source": [
    "# for calculating training execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# create new NN instance\n",
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate is 0.3 (idk why 0.3 so dont ask me)\n",
    "learning_rate = 0.3\n",
    "\n",
    "# create instance of NN\n",
    "n = jirehsNeuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n",
    "\n",
    "training_data_file = open(\"mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "# go through all records in the training data set\n",
    "for record in training_data_list:\n",
    "\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "    # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "    targets = numpy.zeros(output_nodes) + 0.01\n",
    "\n",
    "    # all_values[0] is the target label for this record\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    \n",
    "    n.train(inputs, targets)\n",
    "\n",
    "print(\"Training Completed\")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce13b7ce",
   "metadata": {},
   "source": [
    "#### TE(～￣▽￣)～TING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "155082ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 94.1 %\n",
      "Elapsed time: 2.64 seconds\n"
     ]
    }
   ],
   "source": [
    "test_data_file = open(\"mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "# for calculating testing execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# performance scorecard that counts the accuracy (how many times a positive prediction occured)\n",
    "accuracy_count = []\n",
    "\n",
    "for record in test_data_list:\n",
    "\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    \n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        accuracy_count.append(1)\n",
    "    else:\n",
    "        accuracy_count.append(0)\n",
    "\n",
    "# calculate the performance score\n",
    "accuracy_count_array = numpy.asarray(accuracy_count)\n",
    "print (\"Accuracy =\", (accuracy_count_array.sum() / accuracy_count_array.size) * 100 , \"%\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb22174f",
   "metadata": {},
   "source": [
    "### What happens if I change the Learning Rate? (* ￣︿￣)\n",
    "IDK\n",
    "\n",
    "<img src=\"image3.jpeg\" style=\"width: 50%; height: auto;\">\n",
    "\n",
    "So this is what should happen if I change the learning rate. It shows that 0.2 is the sweetspot for this problem. Basically, having too small a learning rate (like 0.01) is damaging, since it limits the speed at which gradient descent happens, by making the steps too small. On the other hand, the larger learning rate leads to some bouncing around and overshooting during the gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3132cd56",
   "metadata": {},
   "source": [
    "### Epochs (Makes free users of Google Colab cry)\n",
    "Epochs help the weights do gradient descent by providing more chances to creep down those slopes. I hope you understood that. If not, fuck you. \n",
    "\n",
    "Below is an implementation of epochs and new learning rate on the JNN.\n",
    "\n",
    "**Warning:** this is even slower than the previous code. C++ is faster bro. I wonder if there is a JupyterNotebook alternative for C++? I'm not going to google it though. This is already hard enough. Redoing this in C++? lol no thx. What if I have to use pointers? Yeah fuck no. I'll just be ignorant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5664ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate 0.2\n",
      "Epochs: 10\n",
      "Training Completed\n",
      "Training time: 268.31 seconds\n",
      "\n",
      "Accuracy = 95.46 %\n",
      "Testing time: 1.96 seconds\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "# for calculating training execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# create new NN instance\n",
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate is now 0.2 muthafucka\n",
    "learning_rate = 0.2\n",
    "\n",
    "# create instance of NN\n",
    "n = jirehsNeuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n",
    "\n",
    "training_data_file = open(\"mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "\n",
    "        n.train(inputs, targets)\n",
    "\n",
    "\n",
    "print(\"Learning Rate\", learning_rate)\n",
    "print(\"Epochs:\", epochs)\n",
    "\n",
    "print(\"\\nTraining Completed\")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# TESTING\n",
    "test_data_file = open(\"mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "# for calculating testing execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# performance scorecard that counts the accuracy (how many times a positive prediction occured)\n",
    "accuracy_count = []\n",
    "\n",
    "for record in test_data_list:\n",
    "\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    \n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        accuracy_count.append(1)\n",
    "    else:\n",
    "        accuracy_count.append(0)\n",
    "\n",
    "# calculate the performance score\n",
    "accuracy_count_array = numpy.asarray(accuracy_count)\n",
    "print (\"\\nAccuracy =\", (accuracy_count_array.sum() / accuracy_count_array.size) * 100 , \"%\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Testing time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8336f1",
   "metadata": {},
   "source": [
    "Intuition suggests the more training you do the better the performance. Yeah, fuck no. Too much training is actually bad because the network overfits to the training data, and then performs badly against new data that it hasn’t seen before. This overfitting is something to beware of across many different kinds of machine learning, not just neural networks.\n",
    "\n",
    "I already know this from my Data Science specialization. (￣y▽￣)╭ Ohohoho.....\n",
    "\n",
    "<img src=\"image4.jpeg\" style=\"width: 50%; height: auto;\">\n",
    "\n",
    "The 5 or 7 epochs are good. After that performance degrades, and this may be the effect of overfitting. Note that the dip at 6 epochs is probably an unlucky run with the network getting stuck in a bad minimum during gradient descent. Remember that neural network learning is a random process and can sometimes not work ok, and sometimes work really fucking badly.\n",
    "\n",
    "Anyways, further testing should show this;\n",
    "<img src=\"image5.jpeg\" style=\"width: 50%; height: auto;\">\n",
    "Thus, I will be using lr = 0.1 and epoch = 5 from here on out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55bb360",
   "metadata": {},
   "source": [
    "### What about the Hidden Layer Node number? (╬▔皿▔)╯\n",
    "Yeaaaahh im not going to demo that here either. I probably should though just for learning purposes but I already know what happens. So how can it be learning if I already know \n",
    "━━(￣ー￣*|||━━\n",
    "\n",
    "\" The learning capacity of a neural network refers to its ability to learn from input data and improve its performance over time. The learning capacity of a neural network is determined by the architecture of the network and the training process. The architecture of the network refers to the number and arrangement of neurons, or processing units, within the network. The training process involves adjusting the weights and biases of the connections between neurons in order to optimize the network's performance. A neural network with a larger number of neurons or layers will typically have a higher learning capacity, as it will be able to recognize more complex patterns in the input data. However, a larger network also requires more training data and computational resources, and can be more prone to overfitting.\" - **ChatGPT**\n",
    "\n",
    "TLDR: The number of hidden layer nodes directly impact learning capacity which impacts accuracy and a whole lot of other shit.\n",
    "<img src=\"image6.png\" style=\"width: 50%; height: auto;\">\n",
    "So the best node number is 200.\n",
    "\n",
    "Below should be the most optimized JNN. \n",
    "**Warning:** Also takes some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1a5763d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Nodes: 200\n",
      "Learning Rate: 0.2\n",
      "Epochs: 10\n",
      "\n",
      "Training Completed\n",
      "Training time: 439.16 seconds\n",
      "\n",
      "Accuracy = 96.71 %\n",
      "Testing time: 2.78 seconds\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "# for calculating training execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# create new NN instance\n",
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate is now 0.2 muthafucka\n",
    "learning_rate = 0.2\n",
    "\n",
    "# create instance of NN\n",
    "n = jirehsNeuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n",
    "\n",
    "print(\"Hidden Nodes:\", hidden_nodes)\n",
    "print(\"Learning Rate:\", learning_rate)\n",
    "print(\"Epochs:\", epochs)\n",
    "\n",
    "training_data_file = open(\"mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "\n",
    "        n.train(inputs, targets)\n",
    "\n",
    "print(\"\\nTraining Completed\")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# TESTING\n",
    "test_data_file = open(\"mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "# for calculating testing execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# performance scorecard that counts the accuracy (how many times a positive prediction occured)\n",
    "accuracy_count = []\n",
    "\n",
    "for record in test_data_list:\n",
    "\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    \n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        accuracy_count.append(1)\n",
    "    else:\n",
    "        accuracy_count.append(0)\n",
    "\n",
    "# calculate the performance score\n",
    "accuracy_count_array = numpy.asarray(accuracy_count)\n",
    "print (\"\\nAccuracy =\", (accuracy_count_array.sum() / accuracy_count_array.size) * 100 , \"%\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Testing time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a5d47",
   "metadata": {},
   "source": [
    "## TIME TO TEST WITH MY OWN HANDWRITING AHAHAHAHAHAHAH\n",
    "Lets see if it can understand the hieroglyphics that my hands produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_writing_dataset = []\n",
    "\n",
    "# load the png image data as test data set\n",
    "for image_file_name in glob.glob('handwriting/image_?.png'):\n",
    "    \n",
    "    # use the filename to set the correct label\n",
    "    label = int(image_file_name[-5:-4])\n",
    "    \n",
    "    # load image data from png files into an array\n",
    "    print (\"loading ... \", image_file_name)\n",
    "    img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "    \n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "    # scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    print(numpy.min(img_data))\n",
    "    print(numpy.max(img_data))\n",
    "    \n",
    "    # append label and image data  to test data set\n",
    "    record = numpy.append(label,img_data)\n",
    "    my_writing_dataset.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record to test\n",
    "item = 2\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(our_own_dataset[item][1:].reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# correct answer is first value\n",
    "correct_label = our_own_dataset[item][0]\n",
    "# data is remaining values\n",
    "inputs = our_own_dataset[item][1:]\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(inputs)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n",
    "# append correct or incorrect to list\n",
    "if (label == correct_label):\n",
    "    print (\"match!\")\n",
    "else:\n",
    "    print (\"no match!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b138b27",
   "metadata": {},
   "source": [
    "### References\n",
    "- Make Your Own Neural Network (2016) by Tariq Hashi\n",
    "- Some ChatGPT prompts (how do you cite ChatGPT anyway?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
